{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from t2m import Text2Motion\n",
    "from utils.get_opt import get_opt\n",
    "from utils.fixseed import fixseed\n",
    "\n",
    "import torch\n",
    "import numpy as np\n",
    "from os.path import join as pjoin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "denoiser_name = \"t2m_denoiser_vpred_vaegelu\"\n",
    "dataset_name = \"t2m\"\n",
    "generator = Text2Motion(denoiser_name, dataset_name)\n",
    "\n",
    "opt = generator.opt\n",
    "wrapper_opt = get_opt(opt.dataset_opt_path, torch.device(\"cuda\"))\n",
    "mean = np.load(pjoin(wrapper_opt.meta_dir, \"mean.npy\"))\n",
    "std = np.load(pjoin(wrapper_opt.meta_dir, \"std.npy\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Original"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixseed(42)\n",
    "src_text = \"a man is walking\"\n",
    "m_lens = 64\n",
    "cfg_scale = 7.5\n",
    "num_inference_timesteps = 50\n",
    "\n",
    "init_noise, src_motion, (sa, ta, ca) = generator.generate(src_text,\n",
    "                                                          m_lens,\n",
    "                                                          cfg_scale,\n",
    "                                                          num_inference_timesteps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Edit - 4 Different Cases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# edit_text = \"slowly\"\n",
    "edit_text = \"a man is walking while waving his right hand\"\n",
    "src_proportion = 0.2\n",
    "\n",
    "# # case 1: mirror\n",
    "# edit_motion = generator.edit(init_noise,\n",
    "#                              src_text=src_text,\n",
    "#                              edit_text=edit_text,\n",
    "#                              edit_mode=\"mirror\",\n",
    "#                              mirror_mode=\"lower\",\n",
    "#                              cfg_scale=cfg_scale,\n",
    "#                              num_inference_timesteps=num_inference_timesteps,\n",
    "#                              src_sa=sa,\n",
    "#                              src_ta=ta,\n",
    "#                              src_ca=ca,\n",
    "#                              src_proportion=src_proportion)\n",
    "\n",
    "# # case 2: reweight\n",
    "# edit_motion = generator.edit(init_noise,\n",
    "#                              src_text=src_text,\n",
    "#                              edit_text=src_text,\n",
    "#                              edit_mode=\"reweight\",\n",
    "#                              tgt_word=\"high\",\n",
    "#                              reweight_scale=-1.0,\n",
    "#                              cfg_scale=cfg_scale,\n",
    "#                              num_inference_timesteps=num_inference_timesteps,\n",
    "#                              src_sa=sa,\n",
    "#                              src_ta=ta,\n",
    "#                              src_ca=ca,\n",
    "#                              src_proportion=src_proportion)\n",
    "\n",
    "# case 3: refine\n",
    "edit_motion = generator.edit(init_noise,\n",
    "                             src_text=src_text,\n",
    "                             edit_text=edit_text,\n",
    "                             edit_mode=\"refine\",\n",
    "                             cfg_scale=cfg_scale,\n",
    "                             num_inference_timesteps=num_inference_timesteps,\n",
    "                             src_sa=sa,\n",
    "                             src_ta=ta,\n",
    "                             src_ca=ca,\n",
    "                             src_proportion=src_proportion)\n",
    "\n",
    "# # case 4: word swap\n",
    "# edit_motion = generator.edit(init_noise,\n",
    "#                              src_text=src_text,\n",
    "#                              edit_text=edit_text,\n",
    "#                              edit_mode=\"word_swap\",\n",
    "#                              cfg_scale=cfg_scale,\n",
    "#                              num_inference_timesteps=num_inference_timesteps,\n",
    "#                              src_sa=sa,\n",
    "#                              src_ta=None,\n",
    "#                              src_ca=ca,\n",
    "#                              src_proportion=src_proportion,\n",
    "#                              swap_src_proportion=0.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from os.path import join as pjoin\n",
    "import torch\n",
    "import numpy as np\n",
    "from utils.motion_process import recover_from_ric\n",
    "from utils.plot_script import plot_3d_motion\n",
    "from utils.get_opt import get_opt\n",
    "\n",
    "def plot_t2m(data, text, filename):\n",
    "    os.makedirs(\"edit_result\", exist_ok=True)\n",
    "    #data = data[:m_lens[0].item()]\n",
    "    data = data[:m_lens]\n",
    "    joint = recover_from_ric(torch.from_numpy(data).float(), opt.joints_num).numpy()\n",
    "    save_path = pjoin(\"edit_result\", f\"{filename}.mp4\")\n",
    "    plot_3d_motion(save_path, opt.kinematic_chain, joint, title=text, fps=20)\n",
    "\n",
    "    np.save(pjoin(\"edit_result\", f\"{filename}_pos.npy\"), joint)\n",
    "    np.save(pjoin(\"edit_result\", f\"{filename}_feats.npy\"), data)\n",
    "    \n",
    "# mean and std for de-normalization\n",
    "wrapper_opt = get_opt(opt.dataset_opt_path, torch.device('cuda'))\n",
    "mean = np.load(pjoin(wrapper_opt.meta_dir, 'mean.npy'))\n",
    "std = np.load(pjoin(wrapper_opt.meta_dir, 'std.npy'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot Motions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_motion = src_motion.detach().cpu().numpy() * std + mean\n",
    "plot_t2m(src_motion[0], src_text, \"src\")\n",
    "\n",
    "edit_motion = edit_motion.detach().cpu().numpy() * std + mean\n",
    "plot_t2m(edit_motion[0], edit_text, \"edit\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Video Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from moviepy.editor import VideoFileClip, clips_array\n",
    "src_video = VideoFileClip(pjoin(\"edit_result\", \"src.mp4\"))\n",
    "edit_video = VideoFileClip(pjoin(\"edit_result\", \"edit.mp4\"))\n",
    "final_video = clips_array([[src_video, edit_video]])\n",
    "final_video.write_videofile(pjoin(\"edit_result\", \"final.mp4\"))\n",
    "\n",
    "\n",
    "from IPython.display import Video\n",
    "Video(\"edit_result/final.mp4\", width=800, height=400)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "salad",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
